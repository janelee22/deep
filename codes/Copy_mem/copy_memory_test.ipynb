{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO+0qts6T9e6zdgB7uSoaPp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Copy Memory Test__DRNN**"],"metadata":{"id":"gAmwLdc3QyYP"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"58AnSeDyQpYj","executionInfo":{"status":"ok","timestamp":1686534100880,"user_tz":-540,"elapsed":14149,"user":{"displayName":"이승호","userId":"03166614384614211398"}}},"outputs":[],"source":["from torch.utils.tensorboard import SummaryWriter\n","import torch.multiprocessing as mp\n","from torch.autograd import Variable\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import tensorboard\n","from itertools import product\n","import logging\n","from pathlib import Path\n","import time\n","import matplotlib.pyplot as plt\n","import torch.multiprocessing as mp"]},{"cell_type":"code","source":["use_cuda = torch.cuda.is_available()\n","\n","class DRNN(nn.Module):\n","\n","    def __init__(self, n_input, n_hidden, n_layers, dropout=0, cell_type='RNN', batch_first=False):\n","        super(DRNN, self).__init__()\n","\n","        self.dilations = [2 ** i for i in range(n_layers)]\n","        self.cell_type = cell_type\n","        self.batch_first = batch_first\n","\n","        layers = []\n","        if self.cell_type == \"GRU\":\n","            cell = nn.GRU\n","        elif self.cell_type == \"RNN\":\n","            cell = nn.RNN\n","        elif self.cell_type == \"LSTM\":\n","            cell = nn.LSTM\n","        else:\n","            raise NotImplementedError\n","\n","        for i in range(n_layers):\n","            if i == 0:\n","                c = cell(n_input, n_hidden, dropout=dropout)\n","            else:\n","                c = cell(n_hidden, n_hidden, dropout=dropout)\n","            layers.append(c)\n","        self.cells = nn.Sequential(*layers)\n","\n","    def forward(self, inputs, hidden=None):\n","        if self.batch_first:\n","            inputs = inputs.transpose(0, 1)\n","        outputs = []\n","        for i, (cell, dilation) in enumerate(zip(self.cells, self.dilations)):\n","            if hidden is None:\n","                inputs, _ = self.drnn_layer(cell, inputs, dilation)\n","            else:\n","                inputs, hidden[i] = self.drnn_layer(cell, inputs, dilation, hidden[i])\n","\n","            outputs.append(inputs[-dilation:])\n","\n","        if self.batch_first:\n","            inputs = inputs.transpose(0, 1)\n","        return inputs, outputs\n","\n","    def drnn_layer(self, cell, inputs, rate, hidden=None):\n","        n_steps = len(inputs)\n","        batch_size = inputs[0].size(0)\n","        hidden_size = cell.hidden_size\n","\n","        inputs, _ = self._pad_inputs(inputs, n_steps, rate)\n","        dilated_inputs = self._prepare_inputs(inputs, rate)\n","\n","        if hidden is None:\n","            dilated_outputs, hidden = self._apply_cell(dilated_inputs, cell, batch_size, rate, hidden_size)\n","        else:\n","            hidden = self._prepare_inputs(hidden, rate)\n","            dilated_outputs, hidden = self._apply_cell(dilated_inputs, cell, batch_size, rate, hidden_size, hidden=hidden)\n","\n","        splitted_outputs = self._split_outputs(dilated_outputs, rate)\n","        outputs = self._unpad_outputs(splitted_outputs, n_steps)\n","\n","        return outputs, hidden\n","\n","    def _apply_cell(self, dilated_inputs, cell, batch_size, rate, hidden_size, hidden=None):\n","        if hidden is None:\n","            if self.cell_type == 'LSTM':\n","                c, m = self.init_hidden(batch_size * rate, hidden_size)\n","                hidden = (c.unsqueeze(0), m.unsqueeze(0))\n","            else:\n","                hidden = self.init_hidden(batch_size * rate, hidden_size).unsqueeze(0)\n","\n","        dilated_outputs, hidden = cell(dilated_inputs, hidden)\n","\n","        return dilated_outputs, hidden\n","\n","    def _unpad_outputs(self, splitted_outputs, n_steps):\n","        return splitted_outputs[:n_steps]\n","\n","    def _split_outputs(self, dilated_outputs, rate):\n","        batchsize = dilated_outputs.size(1) // rate\n","\n","        blocks = [dilated_outputs[:, i * batchsize: (i + 1) * batchsize, :] for i in range(rate)]\n","\n","        interleaved = torch.stack((blocks)).transpose(1, 0).contiguous()\n","        interleaved = interleaved.view(dilated_outputs.size(0) * rate,\n","                                       batchsize,\n","                                       dilated_outputs.size(2))\n","        return interleaved\n","\n","    def _pad_inputs(self, inputs, n_steps, rate):\n","        is_even = (n_steps % rate) == 0\n","\n","        if not is_even:\n","            dilated_steps = n_steps // rate + 1\n","\n","            zeros_ = torch.zeros(dilated_steps * rate - inputs.size(0),\n","                                 inputs.size(1),\n","                                 inputs.size(2))\n","            if use_cuda:\n","                zeros_ = zeros_.cuda()\n","\n","            inputs = torch.cat((inputs, zeros_))\n","        else:\n","            dilated_steps = n_steps // rate\n","\n","        return inputs, dilated_steps\n","\n","    def _prepare_inputs(self, inputs, rate):\n","        dilated_inputs = torch.cat([inputs[j::rate, :, :] for j in range(rate)], 1)\n","        return dilated_inputs\n","\n","    def init_hidden(self, batch_size, hidden_dim):\n","        hidden = torch.zeros(batch_size, hidden_dim)\n","        if use_cuda:\n","            hidden = hidden.cuda()\n","        if self.cell_type == \"LSTM\":\n","            memory = torch.zeros(batch_size, hidden_dim)\n","            if use_cuda:\n","                memory = memory.cuda()\n","            return (hidden, memory)\n","        else:\n","            return hidden\n"],"metadata":{"id":"l7xdw3PMQ_FL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DRNN_Copy(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, dropout, output_size):\n","        super(DRNN_Copy, self).__init__()\n","        self.drnn = DRNN(cell_type='RNN', dropout=dropout, n_hidden=hidden_size,\n","                         n_input=input_size, n_layers=num_layers, batch_first=True)\n","        self.linear = nn.Linear(hidden_size, output_size)\n","        self.init_weights()\n","\n","    def init_weights(self):\n","        self.linear.weight.data.normal_(0,0.01)\n","\n","    def forward(self, x): # x: (batch, steps, input_size)\n","        y1, _ = self.drnn(x) # y1: (batch, steps, hidden_size)\n","        #import pdb\n","        #pdb.set_trace()\n","        return self.linear(y1) # (batch, steps, output_size)"],"metadata":{"id":"kylUZO8dRBE7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#####model config#####\n","\n","batch_size = 128\n","epochs = 10\n","iters = 30000\n","\n","T = 500\n","#T=1000\n","seq_len = 10\n","n_steps = T + (2 * seq_len)\n","\n","n_classes = 10  # Digits 0 - 9\n","n_train = 1000\n","n_test = 100\n","\n","dropout = 0.0\n","input_size = 1\n","hidden_size = 10\n","num_layers = 9"],"metadata":{"id":"iKObwuC9RBx6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###실험기본세팅###\n","def data_generator_1(T, mem_length, b_size):\n","    \"\"\"\n","    Generate data for the copying memory task\n","\n","    :param T: The total blank time length\n","    :param mem_length: The length of the memory to be recalled\n","    :param b_size: The batch size\n","    :return: Input and target data tensor\n","    \"\"\"\n","    seq = torch.from_numpy(np.random.randint(0, 8, size=(b_size, mem_length))).float()\n","    zeros = 8*torch.zeros((b_size, T))\n","    marker = 9 * torch.ones((b_size, mem_length + 1))\n","    placeholders = torch.zeros((b_size, mem_length))\n","\n","    x = torch.cat((seq, zeros[:, :-1], marker), 1)\n","    y = torch.cat((placeholders, zeros, seq), 1).long()\n","\n","    x, y = Variable(x), Variable(y)\n","    return x, y\n","\n","\n","### 0~2, 0~8 교차###\n","def data_generator_2(T, mem_length, b_size):\n","    \"\"\"\n","    Generate data for the copying memory task\n","\n","    :param T: The total blank time length\n","    :param mem_length: The length of the memory to be recalled\n","    :param b_size: The batch size\n","    :return: Input and target data tensor\n","    \"\"\"\n","    seq1 = torch.from_numpy(np.random.randint(0, 2, size=(b_size,int(mem_length/5)))).float()\n","    seq2 = torch.from_numpy(np.random.randint(0, 8, size=(b_size,int(mem_length/5)))).float()\n","    seq3 = torch.from_numpy(np.random.randint(0, 2, size=(b_size,int(mem_length/5)))).float()\n","    seq4 = torch.from_numpy(np.random.randint(0, 8, size=(b_size,int(mem_length/5)))).float()\n","    seq5 = torch.from_numpy(np.random.randint(0, 2, size=(b_size,int(mem_length/5)))).float()\n","    zeros = 8*torch.zeros((b_size, T))\n","    marker = 9 * torch.ones((b_size, mem_length + 1))\n","    placeholders = torch.zeros((b_size, mem_length))\n","\n","    x = torch.cat((seq1, seq2, seq3, seq4, seq5, zeros[:, :-1], marker), 1)\n","    y = torch.cat((placeholders, zeros, seq1, seq2, seq3, seq4, seq5), 1).long()\n","\n","    x, y = Variable(x), Variable(y)\n","    return x, y\n","\n","###카테고리 수 0~1로 변경###\n","def data_generator_3(T, mem_length, b_size):\n","    \"\"\"\n","    Generate data for the copying memory task\n","\n","    :param T: The total blank time length\n","    :param mem_length: The length of the memory to be recalled\n","    :param b_size: The batch size\n","    :return: Input and target data tensor\n","    \"\"\"\n","    seq = torch.from_numpy(np.random.randint(0, 2, size=(b_size, mem_length))).float()\n","    zeros = 8*torch.zeros((b_size, T))\n","    marker = 9 * torch.ones((b_size, mem_length + 1))\n","    placeholders = torch.zeros((b_size, mem_length))\n","\n","    x = torch.cat((seq, zeros[:, :-1], marker), 1)\n","    y = torch.cat((placeholders, zeros, seq), 1).long()\n","\n","    x, y = Variable(x), Variable(y)\n","    return x, y\n","\n","\n"],"metadata":{"id":"tXzKIWqhRGYZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x, train_y = data_generator_2(T, seq_len,n_train)"],"metadata":{"id":"hmn_FRlJRmbP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = DRNN_Copy(input_size=input_size,\n","                  hidden_size=hidden_size,\n","                  num_layers=num_layers,\n","                  dropout=dropout,\n","                  output_size=n_classes)"],"metadata":{"id":"Gqg9DAoURoUk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","lr = 0.001\n","optimizer = optim.RMSprop(model.parameters(), lr = lr)\n","\n","if torch.cuda.is_available():\n","  model.cuda()\n","  train_x = train_x.cuda()\n","  train_y = train_y.cuda()"],"metadata":{"id":"3rdVlIidRplm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate():\n","    model.eval()\n","    out =  model(test_x.unsqueeze(2).contiguous())\n","    loss = criterion(out.view(-1, n_classes), test_y.view(-1))\n","    pred = out.view(-1, n_classes).data.max(1, keepdim=True)[1]\n","    correct = pred.eq(test_y.data.view_as(pred)).cpu().sum()\n","    counter = out.view(-1, n_classes).size(0)\n","    print('\\nTest set: Average loss: {:.8f}  |  Accuracy: {:.4f}\\n'.format(\n","        loss.data[0], 100. * correct / counter))\n","    return loss.data[0]"],"metadata":{"id":"yk378MARRrDG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(epochs):\n","    global batch_size, seq_len\n","    model.train()\n","    total_loss = 0\n","    start_time = time.time()\n","    correct = 0\n","    counter = 0\n","\n","    for batch_idx, batch in enumerate(range(0, n_train, batch_size)):\n","        start_ind = batch\n","        end_ind = start_ind + batch_size\n","\n","        x = train_x[start_ind:end_ind] # (batch, steps)\n","        y = train_y[start_ind:end_ind] # (batch, steps)\n","        optimizer.zero_grad()\n","        writer = SummaryWriter()\n","\n","        for epoch in range(epochs+1):\n","          out = model(x.unsqueeze(2).contiguous()) # out: (batch, steps, output_size)\n","          loss = criterion(out.view(-1, n_classes), y.view(-1))\n","          writer.add_scalar(\"Loss/train\", loss, epoch)\n","          pred = out.view(-1, n_classes).data.max(1, keepdim=True)[1]\n","          correct += pred.eq(y.data.view_as(pred)).cpu().sum()\n","          counter += out.view(-1, n_classes).size(0)\n","          # if args.clip > 0:\n","          #     torch.nn.utils.clip_grad_norm(model.parameters(), args.clip)\n","          loss.backward()\n","          optimizer.step()\n","          total_loss += loss\n"],"metadata":{"id":"dk0PF3XERtEg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train(100)"],"metadata":{"id":"DZ-NLyLrRwKC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%load_ext tensorboard\n","%tensorboard --logdir runs\n","%tensorboard --logdir runs/exp1\n","%tensorboard --logdir runs/exp1/500"],"metadata":{"id":"IKzkBloyRzKL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Simple_RNN_Vanilla**"],"metadata":{"id":"6QW4vurqSgPf"}},{"cell_type":"code","source":["class RNNModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(RNNModel, self).__init__()\n","\n","        self.hidden_size = hidden_size\n","        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, input, hidden):\n","        output, hidden = self.rnn(input, hidden)\n","        output = self.fc(output)\n","        return output, hidden\n","\n","    def init_hidden(self, batch_size):\n","        return torch.zeros(1, batch_size, self.hidden_size)\n"],"metadata":{"id":"ZFImBks6SnH0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def data_generator_1(T, mem_length):\n","\n","    seq = torch.from_numpy(np.random.randint(0, 8, size=(mem_length,))).float()\n","    blanck = 8 * torch.ones(T)\n","    marker = 9 * torch.ones(mem_length + 1)\n","    placeholders = 8 * torch.ones(mem_length)\n","\n","    x = torch.cat((seq, blanck[:-1], marker), 0)\n","    y = torch.cat((placeholders, blanck, seq), 0).long()\n","\n","    x, y = Variable(x), Variable(y)\n","    return x.unsqueeze(0), y.unsqueeze(0)\n","\n","def data_generator_2(T, mem_length):\n","\n","    seq1 = torch.from_numpy(np.random.randint(0, 2, size=(int(mem_length/5),))).float()\n","    seq2 = torch.from_numpy(np.random.randint(0, 8, size=(int(mem_length/5),))).float()\n","    seq3 = torch.from_numpy(np.random.randint(0, 2, size=(int(mem_length/5),))).float()\n","    seq4 = torch.from_numpy(np.random.randint(0, 8, size=(int(mem_length/5),))).float()\n","    seq5 = torch.from_numpy(np.random.randint(0, 2, size=(int(mem_length/5),))).float()\n","    blanck = 8 * torch.ones(T)\n","    marker = 9 * torch.ones(mem_length + 1)\n","    placeholders = 8 * torch.ones(mem_length)\n","\n","    x = torch.cat((seq1, seq2, seq3, seq4, seq5, blanck[:-1], marker), 0)\n","    y = torch.cat((placeholders, blanck, seq1, seq2, seq3, seq4, seq5), 0).long()\n","\n","    x, y = Variable(x), Variable(y)\n","    return x.unsqueeze(0), y.unsqueeze(0)\n","\n"],"metadata":{"id":"Rl02F-t4TNTW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# setting1\n","input_size = 520\n","hidden_size = 10\n","output_size = 10\n","\n","seq_length = 10\n","batch_size = 1\n","T = 500\n","\n","# # setting2\n","# input_size = 1020\n","# hidden_size = 10\n","# output_size = 10\n","\n","# seq_length = 10\n","# batch_size = 1\n","# T = 1000"],"metadata":{"id":"x2p0fnyzTQIl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x, train_y = data_generator_1(T, seq_length)\n","\n","input_data = train_x.unsqueeze(0)\n","target_data = train_y.unsqueeze(0)"],"metadata":{"id":"2clNqpjTTRim"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.randn(seq_length, batch_size, input_size).size()"],"metadata":{"id":"kBvZPGi_TZ8J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"id":"9XaoxsPPTbWf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = RNNModel(input_size, hidden_size, output_size)\n","if torch.cuda.is_available():\n","  model.cuda()\n","  input_data = input_data.cuda()\n","  target_data = target_data.cuda()\n","\n","# 손실 함수와 옵티마이저\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# 학습 반복\n","num_epochs = 100\n","losses = []\n","for epoch in range(num_epochs):\n","    model.train()\n","    hidden = model.init_hidden(batch_size)\n","    \n","    if torch.cuda.is_available():\n","      hidden = hidden.cuda()\n","    \n","    optimizer.zero_grad()\n","\n","    # 순전파\n","    output, hidden = model(input_data, hidden)\n","\n","    # 손실 계산\n","    loss = criterion(output.squeeze(), target_data[:,:,-10].squeeze())\n","\n","    # 역전파 및 가중치 업데이트\n","    loss.backward()\n","    optimizer.step()\n","    losses.append(loss.item())\n","\n","    # 로그 출력\n","    if (epoch == 0) or ((epoch+1) % 10 == 0):\n","        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"],"metadata":{"id":"c-MQ7n3NTbxO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Simple_RNN_GRU**\n"],"metadata":{"id":"EGIFyZTvTgSY"}},{"cell_type":"code","source":["class GRUModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(GRUModel, self).__init__()\n","\n","        self.hidden_size = hidden_size\n","        self.gru = nn.GRU(input_size, hidden_size)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, input, hidden):\n","        output, hidden = self.gru(input, hidden)\n","        output = self.fc(output)\n","        return output, hidden\n","\n","    def init_hidden(self, batch_size):\n","        return torch.zeros(1, batch_size, self.hidden_size)"],"metadata":{"id":"4EyLkAExToAJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터셋\n","input_size = 520\n","hidden_size = 10\n","output_size = 10\n","\n","seq_length = 10\n","batch_size = 1\n","T = 500\n","\n","train_x, train_y = data_generator_1(T, seq_length)\n","\n","input_data = train_x.unsqueeze(0)\n","target_data = train_y.unsqueeze(0)\n"],"metadata":{"id":"siXAet0MT1D_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.randn(seq_length, batch_size, input_size).size()"],"metadata":{"id":"amOfe1nnT09V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"id":"mGtIVhLiT7vL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = GRUModel(input_size, hidden_size, output_size)\n","if torch.cuda.is_available():\n","  model.cuda()\n","  input_data = input_data.cuda()\n","  target_data = target_data.cuda()\n","\n","# 손실 함수와 옵티마이저\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# 학습 반복\n","num_epochs = 100\n","losses = []\n","for epoch in range(num_epochs):\n","    model.train()\n","    hidden = model.init_hidden(batch_size)\n","    \n","    if torch.cuda.is_available():\n","      hidden = hidden.cuda()\n","    \n","    optimizer.zero_grad()\n","\n","    # 순전파\n","    output, hidden = model(input_data, hidden)\n","\n","    # 손실 계산\n","    loss = criterion(output.squeeze(), target_data[:,:,-10].squeeze())\n","\n","    # 역전파 및 가중치 업데이트\n","    loss.backward()\n","    optimizer.step()\n","    losses.append(loss.item())\n","\n","    # 로그 출력\n","    if (epoch == 0) or ((epoch+1) % 10 == 0):\n","        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"],"metadata":{"id":"hd5Mz0wbT9BE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**StackRNN_Vanilla**"],"metadata":{"id":"D1xWjeykUBet"}},{"cell_type":"code","source":["class StackRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","        super(StackRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, num_classes)\n","\n","    def forward(self, x, hidden):\n","        out, hidden = self.rnn(x, hidden)\n","        out = self.fc(out[:, -1, :])\n","        return out, hidden\n","\n","    def init_hidden(self, batch_size):\n","        return torch.zeros(self.num_layers, batch_size, self.hidden_size)\n"],"metadata":{"id":"NPll844dUJUO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터셋\n","input_size = 1020\n","hidden_size = 10\n","num_layers = 2\n","output_size = 10\n","num_classes = 10  # 클래스 수\n","\n","seq_length = 10\n","batch_size = 1\n","T = 1000\n","\n","train_x, train_y = data_generator_1(T, seq_length)\n","\n","input_data = train_x.unsqueeze(0)\n","target_data = train_y.unsqueeze(0)"],"metadata":{"id":"r7QPY6J8USqE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.randn(seq_length, batch_size, input_size).size()"],"metadata":{"id":"4QoiciKWUULf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"id":"g-RMEedNUV-b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = StackRNN(input_size, hidden_size, num_layers, output_size)\n","if torch.cuda.is_available():\n","  model.cuda()\n","  input_data = input_data.cuda()\n","  target_data = target_data.cuda()\n","\n","# 손실 함수와 옵티마이저\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# 학습\n","num_epochs = 100\n","losses = []\n","\n","for epoch in range(num_epochs):\n","    # 초기 은닉 상태 초기화\n","    hidden = model.init_hidden(input_data.size(0))\n","    if torch.cuda.is_available():\n","      hidden = hidden.cuda()\n","\n","    # Forward 패스\n","    output, hidden = model(input_data, hidden)\n","    loss = criterion(output.squeeze(), target_data[:,:,-10].squeeze())\n","\n","\n","    # Backward 패스 및 최적화\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    # 손실 기록\n","    losses.append(loss.item())\n","    # 로그 출력\n","    if (epoch == 0) or ((epoch+1) % 10 == 0):\n","       print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"],"metadata":{"id":"k8-CPEwKUXRM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**StackRNN_GRU**"],"metadata":{"id":"ANMrfq5PUxj-"}},{"cell_type":"code","source":["class StackGRUModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, output_size):\n","        super(StackGRUModel, self).__init__()\n","\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.stack_gru = nn.GRU(input_size, hidden_size, num_layers)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, input, hidden):\n","        output, hidden = self.stack_gru(input, hidden)\n","        output = self.fc(output)\n","        return output, hidden\n","\n","    def init_hidden(self, batch_size):\n","        return torch.zeros(self.num_layers, batch_size, self.hidden_size)"],"metadata":{"id":"JD5pzZWbU10R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터셋\n","input_size = 520\n","hidden_size = 10\n","num_layers = 2\n","output_size = 10\n","num_classes = 10  # 클래스 수\n","\n","seq_length = 10\n","batch_size = 1\n","T = 500\n","\n","train_x, train_y = data_generator_2(T, seq_length)\n","\n","input_data = train_x.unsqueeze(0)\n","target_data = train_y.unsqueeze(0)"],"metadata":{"id":"8sGHwwenU8Vw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.randn(seq_length, batch_size, input_size).size()"],"metadata":{"id":"jgS6MZIWU-JQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"id":"Jv-DDwdSU_5l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = StackGRUModel(input_size, hidden_size, num_layers, output_size)\n","if torch.cuda.is_available():\n","  model.cuda()\n","  input_data = input_data.cuda()\n","  target_data = target_data.cuda()\n","\n","# 손실 함수와 옵티마이저\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# 학습\n","num_epochs = 100\n","losses = []\n","\n","for epoch in range(num_epochs):\n","    # 초기 은닉 상태 초기화\n","    hidden = model.init_hidden(input_data.size(0))\n","    if torch.cuda.is_available():\n","      hidden = hidden.cuda()\n","\n","    # Forward 패스\n","    output, hidden = model(input_data, hidden)\n","    loss = criterion(output.squeeze(), target_data[:,:,-10].squeeze())\n","\n","\n","    # Backward 패스 및 최적화\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    # 손실 기록\n","    losses.append(loss.item())\n","    # 로그 출력\n","    if (epoch == 0) or ((epoch+1) % 10 == 0):\n","       print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"],"metadata":{"id":"OHJbNk3ZVCTB"},"execution_count":null,"outputs":[]}]}
