{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6mrOlm6mBOd"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import itertools\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.nn import softmax\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, SimpleRNNCell,Flatten\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.layers import RNN, SimpleRNNCell, LSTMCell, GRUCell\n",
        "\n",
        "def dRNN(cell, inputs, rate, scope='default'):\n",
        "\n",
        "    n_steps = len(inputs)\n",
        "    if rate < 0 or rate >= n_steps:\n",
        "        raise ValueError('The \\'rate\\' variable needs to be adjusted.')\n",
        "    print(\"Building layer: %s, input length: %d, dilation rate: %d, input dim: %d.\" % (scope, n_steps, rate, inputs[0].shape[1]))\n",
        "\n",
        "    # make the length of inputs divide 'rate', by using zero-padding\n",
        "    EVEN = (n_steps % rate) == 0\n",
        "    if not EVEN:\n",
        "        # Create a tensor in shape (batch_size, input_dims), which all elements are zero.\n",
        "        # This is used for zero padding\n",
        "        zero_tensor = tf.zeros_like(inputs[0])\n",
        "        dialated_n_steps = n_steps // rate + 1\n",
        "        print(\"=====> %d time points need to be padded. \" % (dialated_n_steps * rate - n_steps))\n",
        "        print(\"=====> Input length for sub-RNN: %d\" % (dialated_n_steps))\n",
        "        for i_pad in range(dialated_n_steps * rate - n_steps):\n",
        "            inputs.append(zero_tensor)\n",
        "    else:\n",
        "        dialated_n_steps = n_steps // rate\n",
        "        print(\"=====> Input length for sub-RNN: %d\" % (dialated_n_steps))\n",
        "\n",
        "\n",
        "    dilated_inputs = [tf.concat(inputs[i * rate:(i + 1) * rate], axis=0) for i in range(dialated_n_steps)]\n",
        "\n",
        "\n",
        "    # building a dilated RNN with reformatted (dilated) inputs\n",
        "    dilated_outputs = tf.keras.layers.RNN(cell, return_sequences=True, return_state=False, go_backwards=False,\n",
        "                                          stateful=False, time_major=True, unroll=False, input_shape=(dialated_n_steps, inputs[0].shape[1]),\n",
        "                                          name=scope)(tf.stack(dilated_inputs))\n",
        "\n",
        "\n",
        "    splitted_outputs = tf.split(dilated_outputs, num_or_size_splits=rate, axis=1)\n",
        "    # unrolled_outputs = [output for sublist in splitted_outputs for output in sublist]\n",
        "    unrolled_outputs = tf.unstack(tf.concat(splitted_outputs, axis=0))\n",
        "    # remove padded zeros\n",
        "    outputs = unrolled_outputs[:n_steps]\n",
        "\n",
        "    return outputs\n",
        "class MyModel(Model):\n",
        "    def __init__(self,  n_classes, rate):\n",
        "        super(MyModel, self).__init__()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        self.softmax = tf.keras.activations.softmax\n",
        "        self.cells = [LSTMCell(50) for _ in range(5)]\n",
        "        self.rate = rate\n",
        "        self.classifier = Dense(n_classes, activation='softmax')\n",
        "        self.dense1 = Dense(128, activation='relu')\n",
        "\n",
        "        self.flatten=Flatten()\n",
        "\n",
        "    def call(self, x):\n",
        "        for i in range(5):\n",
        "            x = dRNN(self.cells[i], x, 2**i)\n",
        "\n",
        "        x = self.dense1(x[-1])\n",
        "\n",
        "        return  self.classifier(x)\n",
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "train_labels_categorical = to_categorical(train_labels)\n",
        "test_labels_categorical = to_categorical(test_labels)\n",
        "# Reshape the data to 2D for SimpleRNN\n",
        "train_images = train_images.reshape((train_images.shape[0], 28*28,1 ))\n",
        "test_images = test_images.reshape((test_images.shape[0], 28*28, 1))\n",
        "\n",
        "# Scale the data\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "def _rnn_reformat(x, input_dims, n_steps):\n",
        "\n",
        "\n",
        "    x_ = tf.transpose(x, [1, 0, 2])\n",
        "\n",
        "    x_ = tf.reshape(x_, [-1, input_dims])\n",
        "\n",
        "    x_reformat = tf.split(x_, n_steps, 0)\n",
        "\n",
        "    return x_reformat\n",
        "\n",
        "x_reformat=_rnn_reformat(train_images, 1, 28*28)\n",
        "x_reformat_test=_rnn_reformat(test_images, 1, 28*28)\n",
        "\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model = MyModel( 10, 1)\n",
        "\n",
        "model.compile(loss='CategoricalCrossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(x_reformat, train_labels_categorical, batch_size=128, epochs=5, validation_data=(x_reformat_test, test_labels_categorical))\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_labels_categorical = to_categorical(train_labels)\n",
        "test_labels_categorical = to_categorical(test_labels)\n",
        "# Reshape the data to 2D for SimpleRNN\n",
        "train_images = train_images.reshape((train_images.shape[0], 28*28,1 ))\n",
        "test_images = test_images.reshape((test_images.shape[0], 28*28, 1))\n",
        "\n",
        "# Scale the data\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "np.random.seed(0)  # Use a fixed seed for reproducibility\n",
        "permutation = np.random.permutation(train_images.shape[1])\n",
        "\n",
        "# Apply the permutation to the data\n",
        "x_train_permuted = train_images[:, permutation,:]\n",
        "x_test_permuted = test_images[:, permutation,:]\n",
        "x_reformat=_rnn_reformat(x_train_permuted, 1, 28*28)\n",
        "x_reformat_test=_rnn_reformat(x_test_permuted, 1, 28*28)\n",
        "class MyModel(Model):\n",
        "    def __init__(self,  n_classes, rate):\n",
        "        super(MyModel, self).__init__()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        self.softmax = tf.keras.activations.softmax\n",
        "        self.cells = [SimpleRNNCell(20) for _ in range(8)]\n",
        "        self.rate = rate\n",
        "        self.classifier = Dense(n_classes, activation='softmax')\n",
        "        self.dense1 = Dense(128, activation='relu')\n",
        "\n",
        "        self.flatten=Flatten()\n",
        "\n",
        "    def call(self, x):\n",
        "        for i in range(8):\n",
        "            x = dRNN(self.cells[i], x, 2**i)\n",
        "\n",
        "        #x = self.dense1(x[-1])\n",
        "\n",
        "        return  self.classifier(x[-1])\n",
        "\n",
        "model = MyModel( 10, 1)\n",
        "\n",
        "model.compile(loss='CategoricalCrossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(x_reformat, train_labels_categorical, batch_size=128, epochs=10, validation_data=(x_reformat_test, test_labels_categorical))\n"
      ]
    }
  ]
}