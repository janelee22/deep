{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "qhA6S8P7S7pB",
        "tS1duU1rS-3J",
        "bDYOyreWeCJO"
      ],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#import"
      ],
      "metadata": {
        "id": "qhA6S8P7S7pB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16FfKdjhSsiL"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import itertools\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.nn import softmax\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, SimpleRNNCell,Flatten\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.layers import RNN, SimpleRNNCell, LSTMCell, GRUCell"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "wIojlSiSSxT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "E9t0ABkmSyix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten, SimpleRNNCell, Conv2D"
      ],
      "metadata": {
        "id": "xsQw6E9eSz3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "dnYvkT0jVWZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DRNN"
      ],
      "metadata": {
        "id": "tS1duU1rS-3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dRNN(cell, inputs, rate, scope='default'):\n",
        "\n",
        "    n_steps = len(inputs)\n",
        "    if rate < 0 or rate >= n_steps:\n",
        "        raise ValueError('The \\'rate\\' variable needs to be adjusted.')\n",
        "    print(\"Building layer: %s, input length: %d, dilation rate: %d, input dim: %d.\" % (scope, n_steps, rate, inputs[0].shape[1]))\n",
        "\n",
        "    # make the length of inputs divide 'rate', by using zero-padding\n",
        "\n",
        "    EVEN = (n_steps % rate) == 0\n",
        "    if not EVEN:\n",
        "        # Create a tensor in shape (batch_size, input_dims), which all elements are zero.\n",
        "        # This is used for zero padding\n",
        "        zero_tensor = tf.zeros_like(inputs[0])\n",
        "        dialated_n_steps = n_steps // rate + 1\n",
        "        print(\"=====> %d time points need to be padded. \" % (dialated_n_steps * rate - n_steps))\n",
        "        print(\"=====> Input length for sub-RNN: %d\" % (dialated_n_steps))\n",
        "        for i_pad in range(dialated_n_steps * rate - n_steps):\n",
        "            inputs.append(zero_tensor)\n",
        "    else:\n",
        "        dialated_n_steps = n_steps // rate\n",
        "        print(\"=====> Input length for sub-RNN: %d\" % (dialated_n_steps))\n",
        "\n",
        "\n",
        "    dilated_inputs = [tf.concat(inputs[i * rate:(i + 1) * rate], axis=0) for i in range(dialated_n_steps)]\n",
        "\n",
        "\n",
        "    # building a dilated RNN with reformatted (dilated) inputs\n",
        "    dilated_outputs = tf.keras.layers.RNN(cell, return_sequences=True, return_state=False, go_backwards=False,\n",
        "                                          stateful=False, time_major=True, unroll=False, input_shape=(dialated_n_steps, inputs[0].shape[1]),\n",
        "                                          name=scope)(tf.stack(dilated_inputs))\n",
        "\n",
        "\n",
        "    splitted_outputs = tf.split(dilated_outputs, num_or_size_splits=rate, axis=1)\n",
        "    # unrolled_outputs = [output for sublist in splitted_outputs for output in sublist]\n",
        "    unrolled_outputs = tf.unstack(tf.concat(splitted_outputs, axis=0))\n",
        "    # remove padded zeros\n",
        "    outputs = unrolled_outputs[:n_steps]\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "KNTARuGxS-SP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#수정Mymodel"
      ],
      "metadata": {
        "id": "bDYOyreWeCJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(Model):\n",
        "    def __init__(self,  n_classes):\n",
        "        super(MyModel, self).__init__()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        self.softmax = tf.keras.activations.softmax\n",
        "        self.cells = [LSTMCell(20) for _ in range(9)]\n",
        "\n",
        "        self.classifier = Dense(n_classes, activation='softmax')\n",
        "        self.dense1 = Dense(128, activation='relu')\n",
        "        self.flatten=Flatten()\n",
        "        self.conv2= Conv2D(filters=10, kernel_size=(1, 4), strides=(1, 1), padding='valid')\n",
        "\n",
        "    def call(self, x):\n",
        "        for i in range(4,9):\n",
        "            x = dRNN(self.cells[i], list(x), 2**i)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        x = tf.stack(x, axis=-1)\n",
        "        x = tf.expand_dims(x, axis=1)\n",
        "\n",
        "        x =self.conv2(x)\n",
        "        x=self.flatten(x)\n",
        "\n",
        "        return  self.classifier(x)"
      ],
      "metadata": {
        "id": "6_GDjPOMaHfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#검증실험1"
      ],
      "metadata": {
        "id": "ha7N3OBhraa6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#min_dilation==4로 설정\n",
        "#마지막에 min_dilation에 대한 conv_layer 추가\n",
        "#drnn 반영\n",
        "\n",
        "###유사도 기준 데이터 클러스터링 실험1\n",
        "#유사도가 높은 데이터가 모두 unit 1,2,3,4에 들어감"
      ],
      "metadata": {
        "id": "bod3AKIgrekZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 로드\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((train_images.shape[0], 28 * 28)) / 255.0\n",
        "test_images = test_images.reshape((test_images.shape[0], 28 * 28)) / 255.0\n",
        "\n",
        "#k-means clustering 시행\n",
        "kmeans = KMeans(n_clusters=2,random_state=2023)\n",
        "kmeans.fit(train_images)\n",
        "cluster_labels = kmeans.labels_\n",
        "\n",
        "clusters = {}\n",
        "for i, label in enumerate(cluster_labels):\n",
        "    if label not in clusters:\n",
        "        clusters[label] = []\n",
        "    clusters[label].append(i)\n",
        "\n",
        "restructured_train_images = []\n",
        "restructured_train_labels = []\n",
        "for cluster in clusters.values():\n",
        "    for i in range(0, len(cluster), 4):\n",
        "        unit = cluster[i:i+4]\n",
        "        restructured_train_images.extend(train_images[unit])\n",
        "        restructured_train_labels.extend(train_labels[unit])\n",
        "\n",
        "restructured_train_images = np.array(restructured_train_images)\n",
        "restructured_train_labels = np.array(restructured_train_labels)\n",
        "\n",
        "#텐서로 바꾸기\n",
        "restructured_train_images = tf.convert_to_tensor(restructured_train_images, dtype=tf.float32)\n",
        "restructured_train_labels = tf.convert_to_tensor(restructured_train_labels, dtype=tf.uint8)\n",
        "train_labels_categorical = to_categorical(restructured_train_labels, num_classes=10)\n",
        "test_labels_categorical = to_categorical(test_labels, num_classes=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBG3hURaaXK6",
        "outputId": "935cf4cd-cc64-4caf-fe74-b1b49c50ccf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "restructured_train_images = tf.reshape(restructured_train_images, (60000, 784, 1))\n",
        "test_images = tf.reshape(test_images, (-1, 784, 1))"
      ],
      "metadata": {
        "id": "ODsitP2naktc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _rnn_reformat(x, input_dims, n_steps):\n",
        "\n",
        "\n",
        "    x_ = tf.transpose(x, [1, 0, 2])\n",
        "\n",
        "    x_ = tf.reshape(x_, [-1, input_dims])\n",
        "\n",
        "    x_reformat = tf.split(x_, n_steps, 0)\n",
        "\n",
        "    return x_reformat\n",
        "\n",
        "x_reformat=_rnn_reformat(restructured_train_images, 1, 28*28)\n",
        "x_reformat_test=_rnn_reformat(test_images , 1, 28*28)"
      ],
      "metadata": {
        "id": "8VgO2qukanMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel( 10)\n",
        "model.compile(loss='CategoricalCrossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "iZzmEf7LarDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_reformat,train_labels_categorical, batch_size=128, epochs=10, validation_data=(x_reformat_test, test_labels_categorical))\n",
        "model.summary()\n",
        "print(model.evaluate(x_reformat_test, test_labels_categorical,verbose=1))"
      ],
      "metadata": {
        "id": "E0WrA1yf4Yso",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b74c5849-6c99-4891-9e4f-eaf53583a454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 15s 47ms/step - loss: 0.1248 - accuracy: 0.9690\n",
            "[0.12478719651699066, 0.968999981880188]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#검증실험2"
      ],
      "metadata": {
        "id": "KZ9ueC5F1zEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###유사도 기준 검증실험2\n",
        "#unit 1기준 유사도가 대비되는 데이터가 unit 2,3,4에 들어감"
      ],
      "metadata": {
        "id": "HVVmZ08IXGUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((train_images.shape[0], 28 * 28)) / 255.0\n",
        "test_images = test_images.reshape((test_images.shape[0], 28 * 28)) / 255.0\n",
        "\n",
        "# k-means 클러스터링\n",
        "kmeans = KMeans(n_clusters=5, random_state=2023)\n",
        "kmeans.fit(train_images)\n",
        "cluster_labels = kmeans.labels_\n",
        "\n",
        "clusters = {}\n",
        "for i, label in enumerate(cluster_labels):\n",
        "    if label not in clusters:\n",
        "        clusters[label] = []\n",
        "    clusters[label].append(i)\n",
        "\n",
        "restructured_train_images = []\n",
        "restructured_train_labels = []\n",
        "\n",
        "# 각 클러스터에서 동일한 개수의 데이터를 선택하여 재구성\n",
        "max_length = max(len(clusters[i]) for i in range(5))\n",
        "\n",
        "for i in range(max_length):\n",
        "    for cluster_name in range(5):  # 0, 1, 2, 3, 4\n",
        "        cluster = clusters[cluster_name]\n",
        "        if i < len(cluster):\n",
        "            unit = cluster[i]\n",
        "            restructured_train_images.append(train_images[unit])\n",
        "            restructured_train_labels.append(train_labels[unit])\n",
        "\n",
        "restructured_train_images = np.array(restructured_train_images)\n",
        "restructured_train_labels = np.array(restructured_train_labels)\n",
        "\n",
        "# 텐서로 변환\n",
        "restructured_train_images = tf.convert_to_tensor(restructured_train_images, dtype=tf.float32)\n",
        "restructured_train_labels = tf.convert_to_tensor(restructured_train_labels, dtype=tf.uint8)\n",
        "train_labels_categorical = to_categorical(restructured_train_labels, num_classes=10)\n",
        "test_labels_categorical = to_categorical(test_labels, num_classes=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C134vYZ4bwSb",
        "outputId": "75ac7715-361c-46e7-e929-81c241a12033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "restructured_train_images = tf.reshape(restructured_train_images, (60000, 784, 1))\n",
        "test_images = tf.reshape(test_images, (-1, 784, 1))\n",
        "\n",
        "def _rnn_reformat(x, input_dims, n_steps):\n",
        "\n",
        "\n",
        "    x_ = tf.transpose(x, [1, 0, 2])\n",
        "\n",
        "    x_ = tf.reshape(x_, [-1, input_dims])\n",
        "\n",
        "    x_reformat = tf.split(x_, n_steps, 0)\n",
        "\n",
        "    return x_reformat\n",
        "\n",
        "x_reformat=_rnn_reformat(restructured_train_images, 1, 28*28)\n",
        "x_reformat_test=_rnn_reformat(test_images , 1, 28*28)"
      ],
      "metadata": {
        "id": "87t9e_4veOox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(10)\n",
        "model.compile(loss='CategoricalCrossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "e9Biybo4QEPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_reformat,train_labels_categorical, batch_size=128, epochs=10, validation_data=(x_reformat_test, test_labels_categorical))\n",
        "model.summary()\n",
        "print(model.evaluate(x_reformat_test, test_labels_categorical,verbose=1))"
      ],
      "metadata": {
        "id": "p6ko05Us3_DF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "767671fe-f63d-4998-a19c-90a1fbbd1cfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 16s 48ms/step - loss: 0.1421 - accuracy: 0.9646\n",
            "[0.1420714557170868, 0.9646000266075134]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#검증실험3"
      ],
      "metadata": {
        "id": "P_a_mJYI20RF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###유사도 기준 검증실험3\n",
        "#unit 1기준 랜덤의 유사도 데이터가 unit 2,3,4에 들어감"
      ],
      "metadata": {
        "id": "Ftme17slXTvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((train_images.shape[0], 28 * 28)) / 255.0\n",
        "test_images = test_images.reshape((test_images.shape[0], 28 * 28)) / 255.0\n",
        "\n",
        "# k-means 클러스터링\n",
        "kmeans = KMeans(n_clusters=5, random_state=2023)\n",
        "kmeans.fit(train_images)\n",
        "cluster_labels = kmeans.labels_\n",
        "\n",
        "clusters = {}\n",
        "for i, label in enumerate(cluster_labels):\n",
        "    if label not in clusters:\n",
        "        clusters[label] = []\n",
        "    clusters[label].append(i)\n",
        "\n",
        "# First, combine all the data from the groups\n",
        "combined_data = []\n",
        "for cluster_name in range(5):  # 0, 1, 2, 3, 4\n",
        "    cluster = clusters[cluster_name]\n",
        "    for unit in cluster:\n",
        "        combined_data.append((train_images[unit], train_labels[unit]))\n",
        "\n",
        "# Now, shuffle the combined data\n",
        "random.shuffle(combined_data)\n",
        "\n",
        "# Finally, split the shuffled data back into images and labels\n",
        "restructured_train_images, restructured_train_labels = zip(*combined_data)\n",
        "\n",
        "restructured_train_images = np.array(restructured_train_images)\n",
        "restructured_train_labels = np.array(restructured_train_labels)\n",
        "\n",
        "# 텐서로 변환\n",
        "restructured_train_images = tf.convert_to_tensor(restructured_train_images, dtype=tf.float32)\n",
        "restructured_train_labels = tf.convert_to_tensor(restructured_train_labels, dtype=tf.uint8)\n",
        "train_labels_categorical = to_categorical(restructured_train_labels, num_classes=10)\n",
        "test_labels_categorical = to_categorical(test_labels, num_classes=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAu6V7hfes8B",
        "outputId": "68a65f9a-2d2c-4284-8927-c1d238e0367d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((train_images.shape[0], 28 * 28)) / 255.0\n",
        "test_images = test_images.reshape((test_images.shape[0], 28 * 28)) / 255.0\n",
        "\n",
        "# 데이터 섞기\n",
        "combined_data = list(zip(train_images, train_labels))\n",
        "random.shuffle(combined_data)\n",
        "\n",
        "restructured_train_images, restructured_train_labels = zip(*combined_data)\n",
        "\n",
        "restructured_train_images = np.array(restructured_train_images)\n",
        "restructured_train_labels = np.array(restructured_train_labels)\n",
        "\n",
        "# 텐서로 변환\n",
        "restructured_train_images = tf.convert_to_tensor(restructured_train_images, dtype=tf.float32)\n",
        "restructured_train_labels = tf.convert_to_tensor(restructured_train_labels, dtype=tf.uint8)\n",
        "train_labels_categorical = to_categorical(restructured_train_labels, num_classes=10)\n",
        "test_labels_categorical = to_categorical(test_labels, num_classes=10)"
      ],
      "metadata": {
        "id": "hHmiR1Nuxrd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(10)\n",
        "model.compile(loss='CategoricalCrossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(x_reformat,train_labels_categorical, batch_size=128, epochs=10, validation_data=(x_reformat_test, test_labels_categorical))"
      ],
      "metadata": {
        "id": "8DegVauURoCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_reformat,train_labels_categorical, batch_size=128, epochs=10, validation_data=(x_reformat_test, test_labels_categorical))\n",
        "model.summary()\n",
        "print(model.evaluate(x_reformat_test, test_labels_categorical))"
      ],
      "metadata": {
        "id": "FzHUYRKs_Z7w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82026dc5-369f-4700-c53f-88c1ef6980bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 16s 48ms/step - loss: 0.1299 - accuracy: 0.9674\n",
            "[0.12989245355129242, 0.9674000144004822]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FXU7r_ve_aBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_rrVW3KrSNJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JLdDDYmnSNM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bF_oHi6cSNQM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}